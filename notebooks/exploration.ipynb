{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2a6eb8",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c20d9",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebcd3be",
   "metadata": {},
   "source": [
    "Data forecasting - the process of using historical and current data to predict future events or trends, employing statistical models and AI/ML techniques to identify patterns and extrapolate them into educated guesses about what might happen next. It serves as a critical planning tool for businesses and other sectors to anticipate change, manage resources, and make informed strategic decisions, though accuracy depends on data quality and chosen methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba33939",
   "metadata": {},
   "source": [
    "READING ALL THE REQUIRED LIBRARIES AND PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe30fa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshutil\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\__init__.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpalettes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrelational\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcategorical\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\relational.py:21\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     adjust_legend_subtitles,\n\u001b[32m     15\u001b[39m     _default_color,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     _scatter_legend_artist,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m groupby_apply_include_groups\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_statistics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EstimateAggregator, WeightedAggregator\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01maxisgrid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FacetGrid, _facet_docs\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_docstrings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringComponents, _core_docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\seaborn\\_statistics.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gaussian_kde\n\u001b[32m     33\u001b[39m     _no_scipy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\stats\\__init__.py:630\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_morestats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_multicomp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_binomtest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m binomtest\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_binned_statistic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\stats\\_multicomp.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minimize_scalar\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfidenceInterval\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_qmc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _var\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _transition_to_rng, DecimalNumber, SeedType\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\stats\\_qmc.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstats\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rng_integers, _rng_spawn, _transition_to_rng\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcsgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minimum_spanning_tree\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distance, Voronoi\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspecial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gammainc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\sparse\\csgraph\\__init__.py:188\u001b[39m\n\u001b[32m    160\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mconnected_components\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    161\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mlaplacian\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    162\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mshortest_path\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mcsgraph_to_masked\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    185\u001b[39m            \u001b[33m'\u001b[39m\u001b[33mNegativeCycleError\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_laplacian\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_shortest_path\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    189\u001b[39m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson, yen,\n\u001b[32m    190\u001b[39m     NegativeCycleError\n\u001b[32m    191\u001b[39m )\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_traversal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    193\u001b[39m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[32m    194\u001b[39m     depth_first_tree, connected_components\n\u001b[32m    195\u001b[39m )\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_min_spanning_tree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minimum_spanning_tree\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/sparse/csgraph/_shortest_path.pyx:21\u001b[39m, in \u001b[36minit scipy.sparse.csgraph._shortest_path\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Wiktor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\sparse\\csgraph\\_validation.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_pydata_sparse_to_scipy\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcsgraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      5\u001b[39m     csgraph_to_dense, csgraph_from_dense,\n\u001b[32m      6\u001b[39m     csgraph_masked_from_dense, csgraph_from_masked\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m DTYPE = np.float64\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_graph\u001b[39m(csgraph, directed, dtype=DTYPE,\n\u001b[32m     13\u001b[39m                    csr_output=\u001b[38;5;28;01mTrue\u001b[39;00m, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     14\u001b[39m                    copy_if_dense=\u001b[38;5;28;01mFalse\u001b[39;00m, copy_if_sparse=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     15\u001b[39m                    null_value_in=\u001b[32m0\u001b[39m, null_value_out=np.inf,\n\u001b[32m     16\u001b[39m                    infinity_null=\u001b[38;5;28;01mTrue\u001b[39;00m, nan_null=\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:645\u001b[39m, in \u001b[36mparent\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bb6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Wiktor\\Downloads\\m5-forecasting-accuracy\\calendar.csv')\n",
    "df1 = pd.read_csv(r'C:\\Users\\Wiktor\\Downloads\\m5-forecasting-accuracy\\sales_train_validation.csv') # Used for training\n",
    "df2 = pd.read_csv(r'C:\\Users\\Wiktor\\Downloads\\m5-forecasting-accuracy\\sell_prices.csv')\n",
    "df3 = pd.read_csv(r'C:\\Users\\Wiktor\\Downloads\\m5-forecasting-accuracy\\sales_train_evaluation.csv') # Used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8081c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
       "0  2011-01-29     11101   Saturday     1      1  2011  d_1          NaN   \n",
       "1  2011-01-30     11101     Sunday     2      1  2011  d_2          NaN   \n",
       "2  2011-01-31     11101     Monday     3      1  2011  d_3          NaN   \n",
       "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          NaN   \n",
       "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          NaN   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          NaN          NaN          NaN        0        0        0  \n",
       "1          NaN          NaN          NaN        0        0        0  \n",
       "2          NaN          NaN          NaN        0        0        0  \n",
       "3          NaN          NaN          NaN        1        1        0  \n",
       "4          NaN          NaN          NaN        1        0        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5db6e9",
   "metadata": {},
   "source": [
    "We can observe that 4 entries (event_name_1, event_name_2, event_type_1, event_name_2) contain NaN(Not a Number) value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523badd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  \\\n",
       "0       CA    0    0    0    0  ...       1       3       0       1       1   \n",
       "1       CA    0    0    0    0  ...       0       0       0       0       0   \n",
       "2       CA    0    0    0    0  ...       2       1       2       1       1   \n",
       "3       CA    0    0    0    0  ...       1       0       5       4       1   \n",
       "4       CA    0    0    0    0  ...       2       1       1       0       1   \n",
       "\n",
       "   d_1909  d_1910  d_1911  d_1912  d_1913  \n",
       "0       1       3       0       1       1  \n",
       "1       1       0       0       0       0  \n",
       "2       1       0       1       1       1  \n",
       "3       0       1       3       7       2  \n",
       "4       1       2       2       2       4  \n",
       "\n",
       "[5 rows x 1919 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02872ff6",
   "metadata": {},
   "source": [
    "Overall we have sales for 1919 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93d3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_id        item_id  wm_yr_wk  sell_price\n",
       "0     CA_1  HOBBIES_1_001     11325        9.58\n",
       "1     CA_1  HOBBIES_1_001     11326        9.58\n",
       "2     CA_1  HOBBIES_1_001     11327        8.26\n",
       "3     CA_1  HOBBIES_1_001     11328        8.26\n",
       "4     CA_1  HOBBIES_1_001     11329        8.26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8f1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
       "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
       "1       CA    0    0    0    0  ...       0       1       2       1       1   \n",
       "2       CA    0    0    0    0  ...       1       0       2       0       0   \n",
       "3       CA    0    0    0    0  ...       1       1       0       4       0   \n",
       "4       CA    0    0    0    0  ...       0       0       0       2       1   \n",
       "\n",
       "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
       "0       0       3       3       0       1  \n",
       "1       0       0       0       0       0  \n",
       "2       0       2       3       0       1  \n",
       "3       1       3       0       2       6  \n",
       "4       0       0       2       1       0  \n",
       "\n",
       "[5 rows x 1947 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f761f",
   "metadata": {},
   "source": [
    "However in the dataset above, we have sales data for 1947 days. Which is why I want to use this dataframe for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4905847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of calendar.csv (1969, 14)\n",
      "Shape of sales_train_validation.csv (30490, 1919)\n",
      "Shape of sell_prices.csv (6841121, 4)\n",
      "Shape of sales_train_evaluation.csv (30490, 1947)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of calendar.csv\", df.shape)\n",
    "print(\"Shape of sales_train_validation.csv\", df1.shape)\n",
    "print(\"Shape of sell_prices.csv\", df2.shape)\n",
    "print(\"Shape of sales_train_evaluation.csv\", df3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0015214",
   "metadata": {},
   "source": [
    "Let's not forget that in calendar.csv file we have many entries with NaN value. Instead we can say that those entries are not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(value = 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e794d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>d</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>11101</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_3</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>11101</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_4</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>11101</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>d_5</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  wm_yr_wk    weekday  wday  month  year    d event_name_1  \\\n",
       "0  2011-01-29     11101   Saturday     1      1  2011  d_1          N/A   \n",
       "1  2011-01-30     11101     Sunday     2      1  2011  d_2          N/A   \n",
       "2  2011-01-31     11101     Monday     3      1  2011  d_3          N/A   \n",
       "3  2011-02-01     11101    Tuesday     4      2  2011  d_4          N/A   \n",
       "4  2011-02-02     11101  Wednesday     5      2  2011  d_5          N/A   \n",
       "\n",
       "  event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0          N/A          N/A          N/A        0        0        0  \n",
       "1          N/A          N/A          N/A        0        0        0  \n",
       "2          N/A          N/A          N/A        0        0        0  \n",
       "3          N/A          N/A          N/A        1        1        0  \n",
       "4          N/A          N/A          N/A        1        0        1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813c165",
   "metadata": {},
   "source": [
    "We need to have days as particular columns, so I had to modify sales_train_evaluation.csv file and assign the changed structure of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r'C:\\Users\\Wiktor\\Downloads\\m5-forecasting-accuracy\\sales_train_validation.csv')\n",
    "l=[]\n",
    "for i in range(1,1914):\n",
    "    l.append(\"d_\"+str(i))\n",
    "df_final=pd.melt(df1,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\\\n",
    "    value_vars=l,var_name=\"d\",value_name=\"sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0a2d8",
   "metadata": {},
   "source": [
    "This is increasing the size of csv file massively, but I don't need that much data.I am taking only last 28 data days of test because eariler values are same as for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd550fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(r'C:\\Users\\Wiktor\\Downloads\\m5-forecasting-accuracy\\sales_train_evaluation.csv')\n",
    "l=[]\n",
    "for i in range(1914,1942):\n",
    "    l.append(\"d_\"+str(i))\n",
    "df_final_test=pd.melt(df3,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\\\n",
    "    value_vars=l,var_name=\"d\",value_name=\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be18e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1942,1970):\n",
    "    df3['d_'+str(i)]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ec704",
   "metadata": {},
   "source": [
    "Now we create the future data that are going to be used for future sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d03a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(1942,1970):\n",
    "    l.append(\"d_\"+str(i))\n",
    "df_future_data=pd.melt(df3,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],\\\n",
    "    value_vars=l,var_name=\"d\",value_name=\"sales\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f40d4e",
   "metadata": {},
   "source": [
    "Let's merge all 3 dfs so we can get the final csv file train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e37d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Wiktor\\Downloads\\m5-forecasting-accuracy\\calendar.csv')\n",
    "df2 = pd.read_csv(r'C:\\Users\\Wiktor\\Downloads\\m5-forecasting-accuracy\\sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_final.merge(df,on='d',copy=False)# combine calender.csv and modified trainevaluation.csv on feature 'd'\n",
    "data=data.merge(df2,on=[\"store_id\", \"item_id\", \"wm_yr_wk\"],copy=False) # combine new dataframe with sell_price.csv usnig features \"store_id\", \"item_id\", \"wm_yr_wk\"\n",
    "# I am storing this final dataframe to final_dataframe.csv\n",
    "data.to_csv('final_dataframe.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we merge all These 3 dataframes to get final csv file test\n",
    "data_test=df_final_test.merge(df,on='d',copy=False)# combine calender.csv and modified trainevaluation.csv on feature 'd'\n",
    "data_test=data_test.merge(df2,on=[\"store_id\", \"item_id\", \"wm_yr_wk\"],copy=False) # combine new dataframe with sell_price.csv usnig features \"store_id\", \"item_id\", \"wm_yr_wk\"\n",
    "# I am storing this final dataframe to final_dataframe.csv\n",
    "data_test.to_csv('final_dataframe_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bfd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we merge all These 3 dataframes to get final csv file future data\n",
    "data_future=df_future_data.merge(df,on='d',copy=False)# combine calender.csv and modified trainevaluation.csv on feature 'd'\n",
    "data_future=data_future.merge(df2,on=[\"store_id\", \"item_id\", \"wm_yr_wk\"],copy=False) # combine new dataframe with sell_price.csv usnig features \"store_id\", \"item_id\", \"wm_yr_wk\"\n",
    "# I am storing this final dataframe to final_future_data.csv\n",
    "data_future.fillna('no_event',inplace=True)\n",
    "data_future.to_csv('final_future_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029acf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of final dataframe train is= (46027957, 22)\n",
      "Shape of final dataframe test is= (853720, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of final dataframe train is=\",data.shape)\n",
    "print(\"Shape of final dataframe test is=\",data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506726cc",
   "metadata": {},
   "source": [
    "We can see that the amount of data is huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e7aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiktor\\AppData\\Local\\Temp\\ipykernel_10564\\1915225771.py:2: DtypeWarning: Columns (14,15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data=pd.read_csv('final_dataframe.csv')\n",
      "C:\\Users\\Wiktor\\AppData\\Local\\Temp\\ipykernel_10564\\1915225771.py:3: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_test=pd.read_csv('final_dataframe_test.csv')\n"
     ]
    }
   ],
   "source": [
    "#reading up complete dataframe\n",
    "data=pd.read_csv('final_dataframe.csv')\n",
    "data_test=pd.read_csv('final_dataframe_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412c878",
   "metadata": {},
   "source": [
    "EXPLORING VARIOUS PROPERTIES OF DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1eb8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head rows of Final DataFrame train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>12</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_010_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_012_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_012</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_015_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_015</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_008_CA_1_validation  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_009_CA_1_validation  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_010_CA_1_validation  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_012_CA_1_validation  HOBBIES_1_012  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_015_CA_1_validation  HOBBIES_1_015  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id    d  sales        date  wm_yr_wk  ... month  year  event_name_1  \\\n",
       "0       CA  d_1     12  2011-01-29     11101  ...     1  2011           NaN   \n",
       "1       CA  d_1      2  2011-01-29     11101  ...     1  2011           NaN   \n",
       "2       CA  d_1      0  2011-01-29     11101  ...     1  2011           NaN   \n",
       "3       CA  d_1      0  2011-01-29     11101  ...     1  2011           NaN   \n",
       "4       CA  d_1      4  2011-01-29     11101  ...     1  2011           NaN   \n",
       "\n",
       "   event_type_1 event_name_2 event_type_2 snap_CA snap_TX  snap_WI  sell_price  \n",
       "0           NaN          NaN          NaN       0       0        0        0.46  \n",
       "1           NaN          NaN          NaN       0       0        0        1.56  \n",
       "2           NaN          NaN          NaN       0       0        0        3.17  \n",
       "3           NaN          NaN          NaN       0       0        0        5.98  \n",
       "4           NaN          NaN          NaN       0       0        0        0.70  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Head rows of Final DataFrame train\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dca715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns present in dataFrame are ['id' 'item_id' 'dept_id' 'cat_id' 'store_id' 'state_id' 'd' 'sales'\n",
      " 'date' 'wm_yr_wk' 'weekday' 'wday' 'month' 'year' 'event_name_1'\n",
      " 'event_type_1' 'event_name_2' 'event_type_2' 'snap_CA' 'snap_TX'\n",
      " 'snap_WI' 'sell_price']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns present in dataFrame are\",data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf33873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here the is a complete information about data Frame is:-\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46027957 entries, 0 to 46027956\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   id            object \n",
      " 1   item_id       object \n",
      " 2   dept_id       object \n",
      " 3   cat_id        object \n",
      " 4   store_id      object \n",
      " 5   state_id      object \n",
      " 6   d             object \n",
      " 7   sales         int64  \n",
      " 8   date          object \n",
      " 9   wm_yr_wk      int64  \n",
      " 10  weekday       object \n",
      " 11  wday          int64  \n",
      " 12  month         int64  \n",
      " 13  year          int64  \n",
      " 14  event_name_1  object \n",
      " 15  event_type_1  object \n",
      " 16  event_name_2  object \n",
      " 17  event_type_2  object \n",
      " 18  snap_CA       int64  \n",
      " 19  snap_TX       int64  \n",
      " 20  snap_WI       int64  \n",
      " 21  sell_price    float64\n",
      "dtypes: float64(1), int64(8), object(13)\n",
      "memory usage: 7.5+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Here the is a complete information about data Frame is:-\\n\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20681b68",
   "metadata": {},
   "source": [
    "Clearly this data frame is using a lot memory(7.5+GB) so we will try to remove unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ba571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are these unique stores in this data= ['CA_1' 'CA_2' 'CA_3' 'CA_4' 'TX_1' 'TX_2' 'TX_3' 'WI_1' 'WI_2' 'WI_3']\n"
     ]
    }
   ],
   "source": [
    "print(\"There are these unique stores in this data=\",data['store_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a075b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are these states in data= ['CA' 'TX' 'WI']\n"
     ]
    }
   ],
   "source": [
    "print(\"There are these states in data=\",data['state_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of wday features= [1 2 3 4 5 6 7]\n",
      "Unique values of weekday features= ['Saturday' 'Sunday' 'Monday' 'Tuesday' 'Wednesday' 'Thursday' 'Friday']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values of wday features=\",data['wday'].unique())\n",
    "print(\"Unique values of weekday features=\",data['weekday'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e0730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years for which I have this sales data= [2011 2012 2013 2014 2015 2016]\n"
     ]
    }
   ],
   "source": [
    "print(\"Years for which I have this sales data=\",data['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a620678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months in year 2016 for which we have data [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Months in year 2016 for which we have data\",data[data['year']==2016]['month'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e0334",
   "metadata": {},
   "source": [
    "DATA ANALYSIS (using bar graphs and pie charts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece58e4",
   "metadata": {},
   "source": [
    "A bar graph that shows average sales for each category, and a pie chart that shows percentage of sales for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818afcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# First, create an aggregated dataframe to avoid repeated groupby operations\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_agg = \u001b[43mdata\u001b[49m.groupby(\u001b[33m'\u001b[39m\u001b[33mcat_id\u001b[39m\u001b[33m'\u001b[39m).agg({\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msales\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m }).reset_index()\n\u001b[32m      5\u001b[39m df_agg.columns = [\u001b[33m'\u001b[39m\u001b[33mcat_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msales_mean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msales_sum\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Calculate percentage\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# First, create an aggregated dataframe to avoid repeated groupby operations\n",
    "df_agg = data.groupby('cat_id').agg({\n",
    "    'sales': ['mean', 'sum']\n",
    "}).reset_index()\n",
    "df_agg.columns = ['cat_id', 'sales_mean', 'sales_sum']\n",
    "\n",
    "# Calculate percentage\n",
    "df_agg['perc'] = df_agg['sales_sum'] / df_agg['sales_sum'].sum() * 100\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Bar plot\n",
    "plt.subplot(121)\n",
    "sns.barplot(x='cat_id', y='sales_mean', data=df_agg)\n",
    "plt.title(\"Bar-Graph for Avg Sales According to each categories\")\n",
    "\n",
    "# Pie chart\n",
    "plt.subplot(122)\n",
    "plt.pie(df_agg['perc'].values, labels=df_agg['cat_id'].values, shadow=True, autopct='%1.1f%%')\n",
    "plt.title(\"Pie Chart showing total sales for each categories\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.groupby('cat_id').mean()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "sns.barplot(x='cat_id',y='sales',data=df)\n",
    "plt.title(\"Bar-Graph for Avg Sales According to each categories\")\n",
    "\n",
    "plt.subplot(122)\n",
    "df=data.groupby('cat_id').sum()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df['perc']=df['sales']/sum(df['sales'].values)*100\n",
    "plt.pie(df['perc'].values,labels=df['cat_id'].values,shadow=True,autopct='%1.1f%%')\n",
    "plt.title(\"Pie Chart showing total sales for each categories\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09147d71",
   "metadata": {},
   "source": [
    "We can clearly see for these graphics above that average and total sales of FOODS are maximum. Let's now create a bar graph for average sales for each State provided, and a pie chart showing the percentage of sales for each State."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c797d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.groupby('state_id').mean()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "sns.barplot(x='state_id',y='sales',data=df)\n",
    "plt.title(\"Bar-Graph for Avg Sales According to each state\")\n",
    "\n",
    "df=data.groupby('state_id').sum()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df['perc']=df['sales']/sum(df['sales'].values)*100\n",
    "plt.subplot(122)\n",
    "plt.pie(df['perc'].values,labels=df['state_id'].values,shadow=True,autopct='%1.1f%%')\n",
    "plt.title(\"Pie Chart Total showing sales for each state\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d956de0",
   "metadata": {},
   "source": [
    "Here we see that the highest average and total sales are in California. Now let's find out the sales and an percentage for each store provided in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356089be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.groupby('store_id').mean()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "sns.barplot(x='store_id',y='sales',data=df)\n",
    "plt.title(\"Bar-Graph for  AVG Sales According to each store\")\n",
    "df=data.groupby('store_id').sum()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df['perc']=df['sales']/sum(df['sales'].values)*100\n",
    "plt.subplot(122)\n",
    "plt.pie(df['perc'].values,labels=df['store_id'].values,shadow=True,autopct='%1.1f%%')\n",
    "plt.title(\"Pie Chart showing total sales for each store\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fa743",
   "metadata": {},
   "source": [
    "The store CA_3 has the maximum total sales and an average. Our next step will be a generation of a bar graph that shows average sales according to each department and a pie chart that shows a percentage of sales for each department. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.groupby('dept_id').mean()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "sns.barplot(x='dept_id',y='sales',data=df)\n",
    "plt.title(\"Bar-Graph for  AVG Sales According to each department\")\n",
    "df=data.groupby('dept_id').sum()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df['perc']=df['sales']/sum(df['sales'].values)*100\n",
    "plt.subplot(122)\n",
    "plt.pie(df['perc'].values,labels=df['dept_id'].values,shadow=True,autopct='%1.1f%%')\n",
    "plt.title(\"Pie Chart showing total sales for each department\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e27f6",
   "metadata": {},
   "source": [
    "FOODS_3 is the department that have the most sales, and HOBBIES_2 is the department that have the least sales. Nearly a half of the sales are done by FOODS_3 department. Let's find out the average sales and a percentage of sales for each week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.groupby('wday').mean()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "sns.barplot(x='wday',y='sales',data=df)\n",
    "plt.title(\"Bar-Graph for AVG Sales According to each week day\")\n",
    "\n",
    "df=data.groupby('wday').sum()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df['perc']=df['sales']/sum(df['sales'].values)*100\n",
    "plt.subplot(122)\n",
    "plt.pie(df['perc'].values,labels=df['wday'].values,shadow=True,autopct='%1.1f%%')\n",
    "plt.title(\"Pie Chart showing Total sales for each week day\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b788db",
   "metadata": {},
   "source": [
    "Based on the information provided, it's important for trying out to use this weekday feature while training our future models. Now let's check how does it look monthly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff91171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.groupby('month').mean()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "sns.barplot(x='month',y='sales',data=df)\n",
    "plt.title(\"Bar-Graph for AVG Sales According to each month\")\n",
    "\n",
    "df=data.groupby('month').sum()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df['perc']=df['sales']/sum(df['sales'].values)*100\n",
    "plt.subplot(122)\n",
    "plt.pie(df['perc'].values,labels=df['month'].values,shadow=True,autopct='%1.1f%%')\n",
    "plt.title(\"Pie Chart showing Total sales for each month\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda7b5c",
   "metadata": {},
   "source": [
    "The average sales are the highest for February. The only time range that remains to check is a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.groupby('year').mean()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "\n",
    "sns.barplot(x='year',y='sales',data=df)\n",
    "plt.title(\"Bar-Graph for AVG Sales According to each year\")\n",
    "\n",
    "plt.subplot(122)\n",
    "df=data.groupby('year').sum()\n",
    "df.reset_index(level=0,inplace=True)\n",
    "df['year_avg']=df['sales']/sum(df['sales'].values)*100\n",
    "plt.pie(df['year_avg'].values,labels=df['year'].values,shadow=True,autopct='%1.1f%%')\n",
    "\n",
    "plt.title(\"pie chart for total Sales According to each year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc3e9f",
   "metadata": {},
   "source": [
    "We have the highest average sales in 2011, and the lowest in 2015. But the total sales are the biggest in 2013."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
