{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7fae47",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b976ee0",
   "metadata": {},
   "source": [
    "## Definition and a summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c814d5eb",
   "metadata": {},
   "source": [
    "Feature engineering - the process of transforming raw data into meaningful input features that better represent the underlying problem, improving the performance and accuracy of machine learning models. This critical data science technique involves selecting, creating, and transforming variables to enhance the data's predictive power and make it more suitable for algorithms to learn from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8519009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import multiprocessing as mp\n",
    "import gc\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import calendar\n",
    "from scipy.sparse import csr_matrix,hstack\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2043f4f",
   "metadata": {},
   "source": [
    "First of all, let's read up the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affe9cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiktor\\AppData\\Local\\Temp\\ipykernel_1340\\2187268715.py:1: DtypeWarning: Columns (14,15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train=pd.read_csv('final_dataframe.csv')\n",
      "C:\\Users\\Wiktor\\AppData\\Local\\Temp\\ipykernel_1340\\2187268715.py:2: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test=pd.read_csv('final_dataframe_test.csv')\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('final_dataframe.csv')\n",
    "test=pd.read_csv('final_dataframe_test.csv')\n",
    "final_test=pd.read_csv('final_future_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa563a3",
   "metadata": {},
   "source": [
    "It took more than 10 minutes to read all the dataframes. It would be easier if I reduce the memory of all of those by converting all categorical variables to integer. Also, we save here label encoders data so we can use them to encode our future unknown data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4590d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl=LabelEncoder()\n",
    "train['item_id']=lbl.fit_transform(train['item_id'])\n",
    "test['item_id']=lbl.transform(test['item_id'])\n",
    "final_test['item_id']=lbl.transform(final_test['item_id'])\n",
    "pickle.dump(lbl,open('label_encoder_item_id.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fcd916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl=LabelEncoder()\n",
    "train['dept_id']=lbl.fit_transform(train['dept_id'])\n",
    "test['dept_id']=lbl.transform(test['dept_id'])\n",
    "final_test['dept_id']=lbl.transform(final_test['dept_id'])\n",
    "pickle.dump(lbl,open('label_encoder_dept_id.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e51df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl=LabelEncoder()\n",
    "train['cat_id']=lbl.fit_transform(train['cat_id'])\n",
    "test['cat_id']=lbl.transform(test['cat_id'])\n",
    "final_test['cat_id']=lbl.transform(final_test['cat_id'])\n",
    "pickle.dump(lbl,open('label_encoder_cat_id.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c4cbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl=LabelEncoder()\n",
    "train['store_id']=lbl.fit_transform(train['store_id'])\n",
    "test['store_id']=lbl.transform(test['store_id'])\n",
    "final_test['store_id']=lbl.transform(final_test['store_id'])\n",
    "pickle.dump(lbl,open('label_encoder_store_id.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7beb2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl=LabelEncoder()\n",
    "train['state_id']=lbl.fit_transform(train['state_id'])\n",
    "test['state_id']=lbl.transform(test['state_id'])\n",
    "final_test['state_id']=lbl.transform(final_test['state_id'])\n",
    "pickle.dump(lbl,open('label_encoder_state_id.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4febd64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle event_name_1 encoding\n",
    "train['event_name_1'] = train['event_name_1'].fillna('no_event')\n",
    "test['event_name_1'] = test['event_name_1'].fillna('no_event')\n",
    "final_test['event_name_1'] = final_test['event_name_1'].fillna('no_event')\n",
    "\n",
    "# Ensure all values are strings\n",
    "train['event_name_1'] = train['event_name_1'].astype(str)\n",
    "test['event_name_1'] = test['event_name_1'].astype(str)\n",
    "final_test['event_name_1'] = final_test['event_name_1'].astype(str)\n",
    "\n",
    "# Combine all values for fitting\n",
    "all_values = np.concatenate([\n",
    "    train['event_name_1'].values,\n",
    "    test['event_name_1'].values,\n",
    "    final_test['event_name_1'].values\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(all_values)\n",
    "train['event_name_1'] = lbl.transform(train['event_name_1'])\n",
    "test['event_name_1'] = lbl.transform(test['event_name_1'])\n",
    "final_test['event_name_1'] = lbl.transform(final_test['event_name_1'])\n",
    "\n",
    "pickle.dump(lbl, open('label_encoder_event_name_1.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5a6c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle event_name_2 encoding\n",
    "train['event_name_2'] = train['event_name_2'].fillna('no_event')\n",
    "test['event_name_2'] = test['event_name_2'].fillna('no_event')\n",
    "final_test['event_name_2'] = final_test['event_name_2'].fillna('no_event')\n",
    "\n",
    "# Ensure all values are strings\n",
    "train['event_name_2'] = train['event_name_2'].astype(str)\n",
    "test['event_name_2'] = test['event_name_2'].astype(str)\n",
    "final_test['event_name_2'] = final_test['event_name_2'].astype(str)\n",
    "\n",
    "# Combine all values for fitting\n",
    "all_values = np.concatenate([\n",
    "    train['event_name_2'].values,\n",
    "    test['event_name_2'].values,\n",
    "    final_test['event_name_2'].values\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(all_values)\n",
    "train['event_name_2'] = lbl.transform(train['event_name_2'])\n",
    "test['event_name_2'] = lbl.transform(test['event_name_2'])\n",
    "final_test['event_name_2'] = lbl.transform(final_test['event_name_2'])\n",
    "\n",
    "pickle.dump(lbl, open('label_encoder_event_name_2.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94410721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle event_type_1 encoding\n",
    "train['event_type_1'] = train['event_type_1'].fillna('no_event')\n",
    "test['event_type_1'] = test['event_type_1'].fillna('no_event')\n",
    "final_test['event_type_1'] = final_test['event_type_1'].fillna('no_event')\n",
    "\n",
    "# Ensure all values are strings\n",
    "train['event_type_1'] = train['event_type_1'].astype(str)\n",
    "test['event_type_1'] = test['event_type_1'].astype(str)\n",
    "final_test['event_type_1'] = final_test['event_type_1'].astype(str)\n",
    "\n",
    "# Combine all values for fitting\n",
    "all_values = np.concatenate([\n",
    "    train['event_type_1'].values,\n",
    "    test['event_type_1'].values,\n",
    "    final_test['event_type_1'].values\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(all_values)\n",
    "train['event_type_1'] = lbl.transform(train['event_type_1'])\n",
    "test['event_type_1'] = lbl.transform(test['event_type_1'])\n",
    "final_test['event_type_1'] = lbl.transform(final_test['event_type_1'])\n",
    "\n",
    "pickle.dump(lbl, open('label_encoder_event_type_1.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f08ba7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle event_type_2 encoding\n",
    "train['event_type_2'] = train['event_type_2'].fillna('no_event')\n",
    "test['event_type_2'] = test['event_type_2'].fillna('no_event')\n",
    "final_test['event_type_2'] = final_test['event_type_2'].fillna('no_event')\n",
    "\n",
    "# Ensure all values are strings\n",
    "train['event_type_2'] = train['event_type_2'].astype(str)\n",
    "test['event_type_2'] = test['event_type_2'].astype(str)\n",
    "final_test['event_type_2'] = final_test['event_type_2'].astype(str)\n",
    "\n",
    "# Combine all values for fitting\n",
    "all_values = np.concatenate([\n",
    "    train['event_type_2'].values,\n",
    "    test['event_type_2'].values,\n",
    "    final_test['event_type_2'].values\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(all_values)\n",
    "train['event_type_2'] = lbl.transform(train['event_type_2'])\n",
    "test['event_type_2'] = lbl.transform(test['event_type_2'])\n",
    "final_test['event_type_2'] = lbl.transform(final_test['event_type_2'])\n",
    "\n",
    "pickle.dump(lbl, open('label_encoder_event_type_2.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a423f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl=LabelEncoder()\n",
    "train['event_type_1']=train['event_type_1'].fillna('no_event')\n",
    "test['event_type_1']=test['event_type_1'].fillna('no_event')\n",
    "final_test['event_type_1']=final_test['event_type_1'].fillna('no_event')\n",
    "train['event_type_1']=lbl.fit_transform(train['event_type_1'])\n",
    "test['event_type_1']=lbl.transform(test['event_type_1'])\n",
    "final_test['event_type_1']=lbl.transform(final_test['event_type_1'])\n",
    "pickle.dump(lbl,open('label_encoder_event_type_1.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59f51351",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl=LabelEncoder()\n",
    "train['event_type_2']=train['event_type_2'].fillna('no_event')\n",
    "test['event_type_2']=test['event_type_2'].fillna('no_event')\n",
    "final_test['event_type_2']=final_test['event_type_2'].fillna('no_event')\n",
    "train['event_type_2']=lbl.fit_transform(train['event_type_2'])\n",
    "test['event_type_2']=lbl.transform(test['event_type_2'])\n",
    "final_test['event_type_2']=lbl.transform(final_test['event_type_2'])\n",
    "pickle.dump(lbl,open('label_encoder_event_type_2.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1ba4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl=LabelEncoder()\n",
    "train['year']=lbl.fit_transform(train['year'])\n",
    "test['year']=lbl.transform(test['year'])\n",
    "final_test['year']=lbl.transform(final_test['year'])\n",
    "pickle.dump(lbl,open('label_encoder_year.sav','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954ffcc",
   "metadata": {},
   "source": [
    "After the data reducing has been done, we can remove unnecessary columns. Firstly, let's convert all 3 state SNAPs into one feature named SNAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4de4f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 14s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.loc[train['state_id'] == 'CA', 'snap'] = train.loc[train['state_id'] == 'CA']['snap_CA']\n",
    "train.loc[train['state_id'] == 'TX', 'snap'] = train.loc[train['state_id'] == 'TX']['snap_TX']\n",
    "train.loc[train['state_id'] == 'WI', 'snap'] = train.loc[train['state_id'] == 'WI']['snap_WI']\n",
    "train.drop(['snap_CA','snap_TX','snap_WI'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "test.loc[test['state_id'] == 'CA', 'snap'] = test.loc[test['state_id'] == 'CA']['snap_CA']\n",
    "test.loc[test['state_id'] == 'TX', 'snap'] = test.loc[test['state_id'] == 'TX']['snap_TX']\n",
    "test.loc[test['state_id'] == 'WI', 'snap'] = test.loc[test['state_id'] == 'WI']['snap_WI']\n",
    "test.drop(['snap_CA','snap_TX','snap_WI'],axis=1,inplace=True)\n",
    "\n",
    "final_test.loc[final_test['state_id'] == 'CA', 'snap'] = final_test.loc[final_test['state_id'] == 'CA']['snap_CA']\n",
    "final_test.loc[final_test['state_id'] == 'TX', 'snap'] = final_test.loc[final_test['state_id'] == 'TX']['snap_TX']\n",
    "final_test.loc[final_test['state_id'] == 'WI', 'snap'] = final_test.loc[final_test['state_id'] == 'WI']['snap_WI']\n",
    "final_test.drop(['snap_CA','snap_TX','snap_WI'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f904d5e",
   "metadata": {},
   "source": [
    "Weekday = wday are similar features so there is no need to keep it. The same reason for having wm_yr_wk feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffe5713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 13s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.drop('weekday',axis=1,inplace=True)\n",
    "train.drop('wm_yr_wk',axis=1,inplace=True)\n",
    " \n",
    "test.drop('weekday',axis=1,inplace=True)\n",
    "test.drop('wm_yr_wk',axis=1,inplace=True)\n",
    "\n",
    "final_test.drop('weekday',axis=1,inplace=True)\n",
    "final_test.drop('wm_yr_wk',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8fc87d",
   "metadata": {},
   "source": [
    "FEATURES THAT INCLUDE TIME INTERVALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d35b4a",
   "metadata": {},
   "source": [
    "a) Number of the week - I created the function to get the week number of particular date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "460cde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_week_number(x):\n",
    "    date=calendar.datetime.date.fromisoformat(x)\n",
    "    return date.isocalendar()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a85b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['week_number']=train['date'].apply(lambda x:get_week_number(x))\n",
    "test['week_number']=test['date'].apply(lambda x:get_week_number(x))\n",
    "final_test['week_number']=final_test['date'].apply(lambda x:get_week_number(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e3e1d",
   "metadata": {},
   "source": [
    "b) Season of the year - A function that is used to get season according to the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22a7532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(x):\n",
    "    if x in [12,1,2]:\n",
    "        return 0      #\"Winter\"\n",
    "    elif x in [3,4,5]:\n",
    "        return 1   #\"Spring\"\n",
    "    elif x in [6,7,8]:\n",
    "        return 2   #\"Summer\"\n",
    "    else:\n",
    "        return 3   #\"Autumn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5d28817",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['season']=train['month'].apply(lambda x:get_season(x))\n",
    "test['season']=test['month'].apply(lambda x:get_season(x))\n",
    "final_test['season']=final_test['month'].apply(lambda x:get_season(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f89bf5",
   "metadata": {},
   "source": [
    "c) Start of a quarter - A function used to check which day starts the quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76a4a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_quarter_begin(x):\n",
    "    day=calendar.datetime.date.fromisoformat(x).day\n",
    "    month=calendar.datetime.date.fromisoformat(x).month\n",
    "    return 1 if (day==1 and (month in [1,4,7,9])) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e6264cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['quarter_start']=train['date'].apply(lambda x:check_if_quarter_begin(x))\n",
    "test['quarter_start']=test['date'].apply(lambda x:check_if_quarter_begin(x))\n",
    "final_test['quarter_start']=final_test['date'].apply(lambda x:check_if_quarter_begin(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d75b4d",
   "metadata": {},
   "source": [
    "d) End of a quarter - A function used to check which day ends the quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61e2d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_quarter_end(x):\n",
    "    day=calendar.datetime.date.fromisoformat(x).day\n",
    "    month=calendar.datetime.date.fromisoformat(x).month\n",
    "    if (day==31 and month==3) or (day==30 and month==6) or (day==30 and month==9) or (day==31 and month==12):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ed262f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['quarter_end']=train['date'].apply(lambda x:check_if_quarter_end(x))\n",
    "test['quarter_end']=test['date'].apply(lambda x:check_if_quarter_end(x))\n",
    "final_test['quarter_end']=final_test['date'].apply(lambda x:check_if_quarter_end(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e38e6",
   "metadata": {},
   "source": [
    "e) Start of a month - The function below checks if the day is beginning of the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b4d6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def month_start(x):\n",
    "    day=calendar.datetime.date.fromisoformat(x).day\n",
    "    return 1 if day==1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05881d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month_start']=train['date'].apply(lambda x:month_start(x))\n",
    "test['month_start']=test['date'].apply(lambda x:month_start(x))\n",
    "final_test['month_start']=final_test['date'].apply(lambda x:month_start(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d5ed9",
   "metadata": {},
   "source": [
    "f) End of a month - The function below checks if the day is end of the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10c31f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_end(x):\n",
    "    day=calendar.datetime.date.fromisoformat(x).day\n",
    "    month=calendar.datetime.date.fromisoformat(x).month\n",
    "    year=calendar.datetime.date.fromisoformat(x).year\n",
    "    leap_yr=(year%4==0) # Checking if it is a leap year\n",
    "    val=(day==31 and month==1) or (day==29 if leap_yr else day==28) or (day==31 and month==3) or (day==30 and month==4) or\\\n",
    "        (day==31 and month==5) or (day==30 and month==6) or (day==31 and month==7) or (day==31 and month==8) or\\\n",
    "        (day==30 and month==9) or (day==31 and month==10) or (day==30 and month==11) or (day==31 and month==12)\n",
    "    return 1 if val else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0d54e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['month_end']=train['date'].apply(lambda x:month_end(x))\n",
    "test['month_end']=test['date'].apply(lambda x:month_end(x))\n",
    "final_test['month_end']=final_test['date'].apply(lambda x:month_end(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decaf4b8",
   "metadata": {},
   "source": [
    "g) Start of a year - The function checking if a given day is the beginning of a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c808667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_start(x):\n",
    "    day=calendar.datetime.date.fromisoformat(x).day\n",
    "    month=calendar.datetime.date.fromisoformat(x).month\n",
    "    return 1 if (day==1 and month==1) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f3bb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year_start']=train['date'].apply(lambda x:year_start(x))\n",
    "test['year_start']=test['date'].apply(lambda x:year_start(x))\n",
    "final_test['year_start']=final_test['date'].apply(lambda x:year_start(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bf558",
   "metadata": {},
   "source": [
    "h) End of a year - The function checking if a given day is the end of a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6197d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_end(x):\n",
    "    day=calendar.datetime.date.fromisoformat(x).day\n",
    "    month=calendar.datetime.date.fromisoformat(x).month\n",
    "    return 1 if (day==31 and month==12) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "deb2e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['year_end']=train['date'].apply(lambda x:year_end(x))\n",
    "test['year_end']=test['date'].apply(lambda x:year_end(x))\n",
    "final_test['year_end']=final_test['date'].apply(lambda x:year_end(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
